{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e28a00-a9ed-4b33-bc2a-fc2783e9508d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from loguru import logger\n",
    "from database.database import db\n",
    "from ml_engineering.pipeline.inference_pipeline.main import InferenceExecutor\n",
    "\n",
    "\n",
    "load_dotenv('../../ml_engineering/pipeline/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eeed7f8-0381-447c-804c-13e37735c6c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:5000/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['MLFLOW_TRACKING_URI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf56969f-018c-4b76-a5bd-cbe77b2efdf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../../data/processed/feature_train.csv', index_col=0)\n",
    "y_train = pd.read_csv('../../data/processed/label_train.csv', index_col=0)\n",
    "X_valid = pd.read_csv('../../data/processed/feature_valid.csv', index_col=0)\n",
    "y_valid = pd.read_csv('../../data/processed/label_valid.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad329d2-c2c4-459b-a52d-e4c932bc5215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"titanic-log-reg-model\"\n",
    "MODEL_URI = \"models://{}/{}/{}\"\n",
    "model_version = mlflow.search_model_versions(filter_string=f\"name='{model_name}'\")[0]\n",
    "model_uri = MODEL_URI.format(model_version.run_id, model_version.name, model_version.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d9f676-a0e8-4826-9e6c-868ef13358fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numerical_cols = ['p_class', 'fare']\n",
    "categorical_cols = ['sex', 'embarked']\n",
    "columns_remove = ['created_at', 'ticket']\n",
    "label = 'survived'\n",
    "query_titanic_train_dataset = f\"SELECT * FROM titanic_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ba27c9-d5bc-4fe6-9dec-02cec7f8a9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inf_executor = InferenceExecutor(db=db)\n",
    "inf_executor.load_latest_model(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "394c4518-dba5-4fe9-9aa0-0c465512ebbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_predict_train = inf_executor.predict(X_train)\n",
    "y_predict_test = inf_executor.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "922cd14c-12c5-49da-88b5-bc82de6c9039",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.22.4\n",
      "  Downloading numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ml-titanic 0.1 requires numpy==1.24.3, but you have numpy 1.22.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.22.4\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.22.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70f2faaf-a081-4e83-bcf0-ee9da1b1ba72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.3\n",
      "1.5.3\n",
      "0.41.0\n",
      "0.12.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap \n",
    "import seaborn\n",
    "\n",
    "print(np.__version__)\n",
    "print(pd.__version__)\n",
    "print(shap.__version__)\n",
    "print(seaborn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2fac5f4-3592-4a57-aa22-637da63ab615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import sklearn\n",
    "\n",
    "\n",
    "model = sklearn.linear_model.LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43e8a88d-7481-4e43-89a1-a7e86078eeef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p_class         float64\n",
       "sex             float64\n",
       "age             float64\n",
       "sib_sp          float64\n",
       "parch           float64\n",
       "fare            float64\n",
       "rank            float64\n",
       "followers       float64\n",
       "title_Dr        float64\n",
       "title_Master    float64\n",
       "title_Miss      float64\n",
       "title_Mr        float64\n",
       "title_Mrs       float64\n",
       "family_0        float64\n",
       "family_1        float64\n",
       "family_2        float64\n",
       "family_3        float64\n",
       "family_4        float64\n",
       "family_5        float64\n",
       "family_6        float64\n",
       "family_7        float64\n",
       "cabin_A         float64\n",
       "cabin_B         float64\n",
       "cabin_C         float64\n",
       "cabin_D         float64\n",
       "cabin_E         float64\n",
       "cabin_F         float64\n",
       "cabin_G         float64\n",
       "cabin_N         float64\n",
       "cabin_T         float64\n",
       "embarked_Q      float64\n",
       "embarked_S      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype(float)\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4090dedc-d46e-421b-be4b-de02d6bfeb97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_normed_summary = shap.kmeans(X_train.values, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e094204-7d36-4bcd-9045-70fc93ccc896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(model.predict, df_train_normed_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "186f1a45-9245-450a-a11a-05e615f5efb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                  | 0/712 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TUL/mlops-titanic/venv/lib/python3.9/site-packages/shap/explainers/_kernel.py:190\u001b[0m, in \u001b[0;36mKernel.shap_values\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_index:\n\u001b[1;32m    189\u001b[0m     data \u001b[38;5;241m=\u001b[39m convert_to_instance_with_index(data, column_name, index_value[i:i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], index_name)\n\u001b[0;32m--> 190\u001b[0m explanations\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgc_collect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    192\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m~/TUL/mlops-titanic/venv/lib/python3.9/site-packages/shap/explainers/_kernel.py:277\u001b[0m, in \u001b[0;36mKernel.explain\u001b[0;34m(self, incoming_instance, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallocate()\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# weight the different subset sizes\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m num_subset_sizes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m(np\u001b[38;5;241m.\u001b[39mceil((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m))\n\u001b[1;32m    278\u001b[0m num_paired_subset_sizes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint(np\u001b[38;5;241m.\u001b[39mfloor((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m))\n\u001b[1;32m    279\u001b[0m weight_vector \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM \u001b[38;5;241m-\u001b[39m i)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_subset_sizes \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)])\n",
      "File \u001b[0;32m~/TUL/mlops-titanic/venv/lib/python3.9/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "shap_values = explainer.shap_values(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3ad7924-4055-4360-ba7f-109c5d3e2f8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p_class</th>\n",
       "      <td>712.0</td>\n",
       "      <td>2.299157</td>\n",
       "      <td>0.836307</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.366573</td>\n",
       "      <td>0.482207</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>712.0</td>\n",
       "      <td>29.786868</td>\n",
       "      <td>13.233471</td>\n",
       "      <td>0.42</td>\n",
       "      <td>21.260</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>36.000</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sib_sp</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.516854</td>\n",
       "      <td>1.134919</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parch</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.391854</td>\n",
       "      <td>0.829885</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>712.0</td>\n",
       "      <td>32.865817</td>\n",
       "      <td>51.481324</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.925</td>\n",
       "      <td>14.4583</td>\n",
       "      <td>31.275</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.973315</td>\n",
       "      <td>0.161276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>followers</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.908708</td>\n",
       "      <td>1.655688</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_Dr</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.007022</td>\n",
       "      <td>0.083564</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_Master</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.039326</td>\n",
       "      <td>0.194506</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_Miss</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.216292</td>\n",
       "      <td>0.412005</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_Mr</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.588483</td>\n",
       "      <td>0.492454</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_Mrs</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.148876</td>\n",
       "      <td>0.356217</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family_0</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.075843</td>\n",
       "      <td>0.264932</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family_1</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.129213</td>\n",
       "      <td>0.335672</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family_2</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.175562</td>\n",
       "      <td>0.380714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family_3</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.183989</td>\n",
       "      <td>0.387747</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family_4</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.188202</td>\n",
       "      <td>0.391148</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family_5</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.198034</td>\n",
       "      <td>0.398798</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family_6</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.191011</td>\n",
       "      <td>0.393374</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family_7</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.189607</td>\n",
       "      <td>0.392265</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabin_A</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.128815</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabin_B</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.050562</td>\n",
       "      <td>0.219255</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabin_C</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.063202</td>\n",
       "      <td>0.243497</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabin_D</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.036517</td>\n",
       "      <td>0.187704</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabin_E</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.037921</td>\n",
       "      <td>0.191140</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabin_F</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.015449</td>\n",
       "      <td>0.123419</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabin_G</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>0.074795</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabin_N</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.772472</td>\n",
       "      <td>0.419531</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabin_T</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.037477</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarked_Q</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.271571</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarked_S</th>\n",
       "      <td>712.0</td>\n",
       "      <td>0.734551</td>\n",
       "      <td>0.441883</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count       mean        std   min     25%      50%     75%  \\\n",
       "p_class       712.0   2.299157   0.836307  1.00   2.000   3.0000   3.000   \n",
       "sex           712.0   0.366573   0.482207  0.00   0.000   0.0000   1.000   \n",
       "age           712.0  29.786868  13.233471  0.42  21.260  30.0000  36.000   \n",
       "sib_sp        712.0   0.516854   1.134919  0.00   0.000   0.0000   1.000   \n",
       "parch         712.0   0.391854   0.829885  0.00   0.000   0.0000   0.000   \n",
       "fare          712.0  32.865817  51.481324  0.00   7.925  14.4583  31.275   \n",
       "rank          712.0   0.973315   0.161276  0.00   1.000   1.0000   1.000   \n",
       "followers     712.0   0.908708   1.655688  0.00   0.000   0.0000   1.000   \n",
       "title_Dr      712.0   0.007022   0.083564  0.00   0.000   0.0000   0.000   \n",
       "title_Master  712.0   0.039326   0.194506  0.00   0.000   0.0000   0.000   \n",
       "title_Miss    712.0   0.216292   0.412005  0.00   0.000   0.0000   0.000   \n",
       "title_Mr      712.0   0.588483   0.492454  0.00   0.000   1.0000   1.000   \n",
       "title_Mrs     712.0   0.148876   0.356217  0.00   0.000   0.0000   0.000   \n",
       "family_0      712.0   0.075843   0.264932  0.00   0.000   0.0000   0.000   \n",
       "family_1      712.0   0.129213   0.335672  0.00   0.000   0.0000   0.000   \n",
       "family_2      712.0   0.175562   0.380714  0.00   0.000   0.0000   0.000   \n",
       "family_3      712.0   0.183989   0.387747  0.00   0.000   0.0000   0.000   \n",
       "family_4      712.0   0.188202   0.391148  0.00   0.000   0.0000   0.000   \n",
       "family_5      712.0   0.198034   0.398798  0.00   0.000   0.0000   0.000   \n",
       "family_6      712.0   0.191011   0.393374  0.00   0.000   0.0000   0.000   \n",
       "family_7      712.0   0.189607   0.392265  0.00   0.000   0.0000   0.000   \n",
       "cabin_A       712.0   0.016854   0.128815  0.00   0.000   0.0000   0.000   \n",
       "cabin_B       712.0   0.050562   0.219255  0.00   0.000   0.0000   0.000   \n",
       "cabin_C       712.0   0.063202   0.243497  0.00   0.000   0.0000   0.000   \n",
       "cabin_D       712.0   0.036517   0.187704  0.00   0.000   0.0000   0.000   \n",
       "cabin_E       712.0   0.037921   0.191140  0.00   0.000   0.0000   0.000   \n",
       "cabin_F       712.0   0.015449   0.123419  0.00   0.000   0.0000   0.000   \n",
       "cabin_G       712.0   0.005618   0.074795  0.00   0.000   0.0000   0.000   \n",
       "cabin_N       712.0   0.772472   0.419531  0.00   1.000   1.0000   1.000   \n",
       "cabin_T       712.0   0.001404   0.037477  0.00   0.000   0.0000   0.000   \n",
       "embarked_Q    712.0   0.080056   0.271571  0.00   0.000   0.0000   0.000   \n",
       "embarked_S    712.0   0.734551   0.441883  0.00   0.000   1.0000   1.000   \n",
       "\n",
       "                   max  \n",
       "p_class         3.0000  \n",
       "sex             1.0000  \n",
       "age            80.0000  \n",
       "sib_sp          8.0000  \n",
       "parch           6.0000  \n",
       "fare          512.3292  \n",
       "rank            1.0000  \n",
       "followers      10.0000  \n",
       "title_Dr        1.0000  \n",
       "title_Master    1.0000  \n",
       "title_Miss      1.0000  \n",
       "title_Mr        1.0000  \n",
       "title_Mrs       1.0000  \n",
       "family_0        1.0000  \n",
       "family_1        1.0000  \n",
       "family_2        1.0000  \n",
       "family_3        1.0000  \n",
       "family_4        1.0000  \n",
       "family_5        1.0000  \n",
       "family_6        1.0000  \n",
       "family_7        1.0000  \n",
       "cabin_A         1.0000  \n",
       "cabin_B         1.0000  \n",
       "cabin_C         1.0000  \n",
       "cabin_D         1.0000  \n",
       "cabin_E         1.0000  \n",
       "cabin_F         1.0000  \n",
       "cabin_G         1.0000  \n",
       "cabin_N         1.0000  \n",
       "cabin_T         1.0000  \n",
       "embarked_Q      1.0000  \n",
       "embarked_S      1.0000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats = X_train.describe()\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15a80215-4354-434f-843c-7f0c7af6011d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_class</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sib_sp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>rank</th>\n",
       "      <th>followers</th>\n",
       "      <th>title_Dr</th>\n",
       "      <th>title_Master</th>\n",
       "      <th>...</th>\n",
       "      <th>cabin_B</th>\n",
       "      <th>cabin_C</th>\n",
       "      <th>cabin_D</th>\n",
       "      <th>cabin_E</th>\n",
       "      <th>cabin_F</th>\n",
       "      <th>cabin_G</th>\n",
       "      <th>cabin_N</th>\n",
       "      <th>cabin_T</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.838021</td>\n",
       "      <td>-0.760198</td>\n",
       "      <td>-0.097243</td>\n",
       "      <td>-0.45541</td>\n",
       "      <td>-0.472178</td>\n",
       "      <td>-0.497979</td>\n",
       "      <td>0.165465</td>\n",
       "      <td>-0.54884</td>\n",
       "      <td>-0.084037</td>\n",
       "      <td>-0.202184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230607</td>\n",
       "      <td>-0.259560</td>\n",
       "      <td>-0.194545</td>\n",
       "      <td>-0.198395</td>\n",
       "      <td>-0.125179</td>\n",
       "      <td>-0.075112</td>\n",
       "      <td>0.542339</td>\n",
       "      <td>-0.037477</td>\n",
       "      <td>-0.294789</td>\n",
       "      <td>-1.662320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>-0.357713</td>\n",
       "      <td>1.313599</td>\n",
       "      <td>-0.210592</td>\n",
       "      <td>-0.45541</td>\n",
       "      <td>-0.472178</td>\n",
       "      <td>-0.434445</td>\n",
       "      <td>0.165465</td>\n",
       "      <td>-0.54884</td>\n",
       "      <td>-0.084037</td>\n",
       "      <td>-0.202184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230607</td>\n",
       "      <td>-0.259560</td>\n",
       "      <td>-0.194545</td>\n",
       "      <td>5.033362</td>\n",
       "      <td>-0.125179</td>\n",
       "      <td>-0.075112</td>\n",
       "      <td>-1.841275</td>\n",
       "      <td>-0.037477</td>\n",
       "      <td>-0.294789</td>\n",
       "      <td>0.600724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>-1.553446</td>\n",
       "      <td>-0.760198</td>\n",
       "      <td>-0.135026</td>\n",
       "      <td>-0.45541</td>\n",
       "      <td>-0.472178</td>\n",
       "      <td>-0.122682</td>\n",
       "      <td>0.165465</td>\n",
       "      <td>-0.54884</td>\n",
       "      <td>-0.084037</td>\n",
       "      <td>-0.202184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230607</td>\n",
       "      <td>3.847259</td>\n",
       "      <td>-0.194545</td>\n",
       "      <td>-0.198395</td>\n",
       "      <td>-0.125179</td>\n",
       "      <td>-0.075112</td>\n",
       "      <td>-1.841275</td>\n",
       "      <td>-0.037477</td>\n",
       "      <td>-0.294789</td>\n",
       "      <td>0.600724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>-1.553446</td>\n",
       "      <td>-0.760198</td>\n",
       "      <td>0.272274</td>\n",
       "      <td>-0.45541</td>\n",
       "      <td>-0.472178</td>\n",
       "      <td>-0.638403</td>\n",
       "      <td>0.165465</td>\n",
       "      <td>-0.54884</td>\n",
       "      <td>-0.084037</td>\n",
       "      <td>-0.202184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230607</td>\n",
       "      <td>-0.259560</td>\n",
       "      <td>-0.194545</td>\n",
       "      <td>-0.198395</td>\n",
       "      <td>-0.125179</td>\n",
       "      <td>-0.075112</td>\n",
       "      <td>0.542339</td>\n",
       "      <td>-0.037477</td>\n",
       "      <td>-0.294789</td>\n",
       "      <td>0.600724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.838021</td>\n",
       "      <td>-0.760198</td>\n",
       "      <td>-0.966252</td>\n",
       "      <td>-0.45541</td>\n",
       "      <td>-0.472178</td>\n",
       "      <td>-0.470138</td>\n",
       "      <td>0.165465</td>\n",
       "      <td>-0.54884</td>\n",
       "      <td>-0.084037</td>\n",
       "      <td>-0.202184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230607</td>\n",
       "      <td>-0.259560</td>\n",
       "      <td>-0.194545</td>\n",
       "      <td>-0.198395</td>\n",
       "      <td>-0.125179</td>\n",
       "      <td>-0.075112</td>\n",
       "      <td>0.542339</td>\n",
       "      <td>-0.037477</td>\n",
       "      <td>-0.294789</td>\n",
       "      <td>0.600724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      p_class       sex       age   sib_sp     parch      fare      rank  \\\n",
       "57   0.838021 -0.760198 -0.097243 -0.45541 -0.472178 -0.497979  0.165465   \n",
       "717 -0.357713  1.313599 -0.210592 -0.45541 -0.472178 -0.434445  0.165465   \n",
       "431 -1.553446 -0.760198 -0.135026 -0.45541 -0.472178 -0.122682  0.165465   \n",
       "633 -1.553446 -0.760198  0.272274 -0.45541 -0.472178 -0.638403  0.165465   \n",
       "163  0.838021 -0.760198 -0.966252 -0.45541 -0.472178 -0.470138  0.165465   \n",
       "\n",
       "     followers  title_Dr  title_Master  ...   cabin_B   cabin_C   cabin_D  \\\n",
       "57    -0.54884 -0.084037     -0.202184  ... -0.230607 -0.259560 -0.194545   \n",
       "717   -0.54884 -0.084037     -0.202184  ... -0.230607 -0.259560 -0.194545   \n",
       "431   -0.54884 -0.084037     -0.202184  ... -0.230607  3.847259 -0.194545   \n",
       "633   -0.54884 -0.084037     -0.202184  ... -0.230607 -0.259560 -0.194545   \n",
       "163   -0.54884 -0.084037     -0.202184  ... -0.230607 -0.259560 -0.194545   \n",
       "\n",
       "      cabin_E   cabin_F   cabin_G   cabin_N   cabin_T  embarked_Q  embarked_S  \n",
       "57  -0.198395 -0.125179 -0.075112  0.542339 -0.037477   -0.294789   -1.662320  \n",
       "717  5.033362 -0.125179 -0.075112 -1.841275 -0.037477   -0.294789    0.600724  \n",
       "431 -0.198395 -0.125179 -0.075112 -1.841275 -0.037477   -0.294789    0.600724  \n",
       "633 -0.198395 -0.125179 -0.075112  0.542339 -0.037477   -0.294789    0.600724  \n",
       "163 -0.198395 -0.125179 -0.075112  0.542339 -0.037477   -0.294789    0.600724  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm(x):\n",
    "    return (x - train_stats['mean']) / train_stats['std']\n",
    "\n",
    "df_train_normed = norm(X_train)\n",
    "\n",
    "df_train_normed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f252065c-f745-4130-bbe0-e16426635b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.LinearRegression().fit(df_train_normed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c56e6a3f-9c23-4316-acfa-67bdac31a1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_normed_summary = shap.kmeans(df_train_normed.values, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c7944b4-6fac-4a3c-8405-f400f4cab0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(model.predict, df_train_normed_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d2215ee2-3b54-46ac-b005-2b311a76d189",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                  | 0/712 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train_normed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TUL/mlops-titanic/venv/lib/python3.9/site-packages/shap/explainers/_kernel.py:190\u001b[0m, in \u001b[0;36mKernel.shap_values\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_index:\n\u001b[1;32m    189\u001b[0m     data \u001b[38;5;241m=\u001b[39m convert_to_instance_with_index(data, column_name, index_value[i:i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], index_name)\n\u001b[0;32m--> 190\u001b[0m explanations\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgc_collect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    192\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m~/TUL/mlops-titanic/venv/lib/python3.9/site-packages/shap/explainers/_kernel.py:277\u001b[0m, in \u001b[0;36mKernel.explain\u001b[0;34m(self, incoming_instance, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallocate()\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# weight the different subset sizes\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m num_subset_sizes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m(np\u001b[38;5;241m.\u001b[39mceil((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m))\n\u001b[1;32m    278\u001b[0m num_paired_subset_sizes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint(np\u001b[38;5;241m.\u001b[39mfloor((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m))\n\u001b[1;32m    279\u001b[0m weight_vector \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM \u001b[38;5;241m-\u001b[39m i)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_subset_sizes \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)])\n",
      "File \u001b[0;32m~/TUL/mlops-titanic/venv/lib/python3.9/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "shap_values = explainer.shap_values(df_train_normed.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743d2f0a-6bb1-47d0-bc3b-0245bd2afdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
